{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71309845-3e78-40d0-b41c-380437fbc666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of           price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  \\\n",
       "0      221900.0         3       1.00         1180      5650     1.0   \n",
       "1      538000.0         3       2.25         2570      7242     2.0   \n",
       "2      180000.0         2       1.00          770     10000     1.0   \n",
       "3      604000.0         4       3.00         1960      5000     1.0   \n",
       "4      510000.0         3       2.00         1680      8080     1.0   \n",
       "...         ...       ...        ...          ...       ...     ...   \n",
       "21608  360000.0         3       2.50         1530      1131     3.0   \n",
       "21609  400000.0         4       2.50         2310      5813     2.0   \n",
       "21610  402101.0         2       0.75         1020      1350     2.0   \n",
       "21611  400000.0         3       2.50         1600      2388     2.0   \n",
       "21612  325000.0         2       0.75         1020      1076     2.0   \n",
       "\n",
       "       waterfront  view  condition  grade  sqft_above  sqft_basement  \\\n",
       "0               0     0          3      7        1180              0   \n",
       "1               0     0          3      7        2170            400   \n",
       "2               0     0          3      6         770              0   \n",
       "3               0     0          5      7        1050            910   \n",
       "4               0     0          3      8        1680              0   \n",
       "...           ...   ...        ...    ...         ...            ...   \n",
       "21608           0     0          3      8        1530              0   \n",
       "21609           0     0          3      8        2310              0   \n",
       "21610           0     0          3      7        1020              0   \n",
       "21611           0     0          3      8        1600              0   \n",
       "21612           0     0          3      7        1020              0   \n",
       "\n",
       "       yr_built  yr_renovated      lat     long  sqft_living15  sqft_lot15  \n",
       "0          1955             0  47.5112 -122.257           1340        5650  \n",
       "1          1951          1991  47.7210 -122.319           1690        7639  \n",
       "2          1933             0  47.7379 -122.233           2720        8062  \n",
       "3          1965             0  47.5208 -122.393           1360        5000  \n",
       "4          1987             0  47.6168 -122.045           1800        7503  \n",
       "...         ...           ...      ...      ...            ...         ...  \n",
       "21608      2009             0  47.6993 -122.346           1530        1509  \n",
       "21609      2014             0  47.5107 -122.362           1830        7200  \n",
       "21610      2009             0  47.5944 -122.299           1020        2007  \n",
       "21611      2004             0  47.5345 -122.069           1410        1287  \n",
       "21612      2008             0  47.5941 -122.299           1020        1357  \n",
       "\n",
       "[21613 rows x 18 columns]>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv ('kc_house_data.csv')\n",
    "df = df.drop(columns=['id', 'date', 'zipcode'])\n",
    "df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef8bdef-c4c3-4a89-aca7-08f3376bee0b",
   "metadata": {},
   "source": [
    "Problem 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f080d06-b514-4c59-9cf7-56903a300b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept (θ₀): 520.414834000001\n",
      "\n",
      "coefficients:\n",
      "bedrooms: -12.5220\n",
      "bathrooms: 18.5276\n",
      "sqft_living: 56.7488\n",
      "sqft_lot: 10.8819\n",
      "floors: 8.0437\n",
      "waterfront: 63.7429\n",
      "view: 48.2001\n",
      "condition: 12.9643\n",
      "grade: 92.2315\n",
      "sqft_above: 48.2901\n",
      "sqft_basement: 27.1370\n",
      "yr_built: -67.6431\n",
      "yr_renovated: 17.2714\n",
      "lat: 78.3757\n",
      "long: -1.0352\n",
      "sqft_living15: 45.5777\n",
      "sqft_lot15: -12.9301\n",
      "\n",
      "training MSE: 31486.1678\n",
      "training R²: 0.7265\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "# drop columns\n",
    "df_train = df_train.drop(columns=['id', 'date', 'zipcode'], errors='ignore')\n",
    "df_test = df_test.drop(columns=['id', 'date', 'zipcode'], errors='ignore')\n",
    "\n",
    "# drop unnamed index\n",
    "df_train = df_train.drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "df_test = df_test.drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "\n",
    "# separate features and target\n",
    "feature_columns = [col for col in df_train.columns if col != 'price']\n",
    "X_train = df_train[feature_columns].values\n",
    "y_train = df_train['price'].values\n",
    "\n",
    "# scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# divide price by 1000\n",
    "y_train_scaled = y_train / 1000\n",
    "\n",
    "# train model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# get coefficients\n",
    "print(\"intercept (θ₀):\", model.intercept_)\n",
    "print(\"\\ncoefficients:\")\n",
    "for i, feature in enumerate(feature_columns):\n",
    "    print(f\"{feature}: {model.coef_[i]:.4f}\")\n",
    "\n",
    "# predictions on training set\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "\n",
    "# calculate metrics\n",
    "train_mse = mean_squared_error(y_train_scaled, y_train_pred)\n",
    "train_r2 = r2_score(y_train_scaled, y_train_pred)\n",
    "\n",
    "print(f\"\\ntraining MSE: {train_mse:.4f}\")\n",
    "print(f\"training R²: {train_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10dcfe2-fb92-40f9-ba55-b5dd9c249cba",
   "metadata": {},
   "source": [
    "Problem 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1c14ff7-4634-4dba-9dd8-132615ea0d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 57628.1547\n",
      "R2: 0.6544\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "X_test = df_test[feature_columns].values\n",
    "Y_test = df_test['price'].values\n",
    "\n",
    "# applies transformation\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "Y_test_scaled = Y_test / 1000\n",
    "\n",
    "# predictiom\n",
    "Y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# calculates test metrics\n",
    "test_mse = mean_squared_error(Y_test_scaled, Y_test_pred)\n",
    "test_r2 = r2_score(Y_test_scaled, Y_test_pred)\n",
    "\n",
    "print(f\"MSE: {test_mse:.4f}\")\n",
    "print(f\"R2: {test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9033bf-4f1a-4a6e-815f-89fc151cfffd",
   "metadata": {},
   "source": [
    "Problem 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f72025-783e-4b3a-86f0-9338fa1e1112",
   "metadata": {},
   "source": [
    "The features that contributed most are grade, lat, yr_built, and waterfront, given their large coefficients. A variance of 73% shows a good fit, and a 0.65 on test is decent. The average error is about $240,000. Test MSE is almost 2x train MSE, which shows overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7ec3ba-0f7f-492f-889c-c1a10ef59d1f",
   "metadata": {},
   "source": [
    "Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09993801-4530-4aef-b140-e00f8fcef7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my implementation:\n",
      "intercept: 520.4148\n",
      "\n",
      "coefficients:\n",
      "bedrooms: 8.5390\n",
      "bathrooms: 34.9387\n",
      "sqft_living: -201.7635\n",
      "sqft_lot: 7.1858\n",
      "floors: -10.7598\n",
      "waterfront: 62.0629\n",
      "view: 55.2758\n",
      "condition: 14.4307\n",
      "grade: 87.0247\n",
      "sqft_above: 271.5224\n",
      "sqft_basement: 94.3658\n",
      "yr_built: -67.6431\n",
      "yr_renovated: 17.2714\n",
      "lat: 78.3757\n",
      "long: -1.0352\n",
      "sqft_living15: 45.5777\n",
      "sqft_lot15: -12.9301\n",
      "\n",
      "train MSE: 34322.5211\n",
      "train R2: 0.7019\n",
      "\n",
      "test MSE: 62327.2177\n",
      "test R²: 0.6262\n",
      "\n",
      "comparison\n",
      "sklearn train MSE: 31486.1678, my MSE: 34322.5211\n",
      "sklearn train R²: 0.7265, my R²: 0.7019\n"
     ]
    }
   ],
   "source": [
    "# use the same preprocessed data from problem 2\n",
    "X_train_bias = np.c_[np.ones(X_train_scaled.shape[0]), X_train_scaled]\n",
    "\n",
    "# closed-form solution\n",
    "theta = np.linalg.inv(X_train_bias.T @ X_train_bias) @ X_train_bias.T @ y_train_scaled\n",
    "\n",
    "print(\"my implementation:\")\n",
    "print(f\"intercept: {theta[0]:.4f}\")\n",
    "print(\"\\ncoefficients:\")\n",
    "for i, feature in enumerate(feature_columns):\n",
    "    print(f\"{feature}: {theta[i+1]:.4f}\")\n",
    "\n",
    "# predictions\n",
    "y_train_pred_manual = X_train_bias @ theta\n",
    "\n",
    "# metrics\n",
    "manual_train_mse = mean_squared_error(y_train_scaled, y_train_pred_manual)\n",
    "manual_train_r2 = r2_score(y_train_scaled, y_train_pred_manual)\n",
    "\n",
    "print(f\"\\ntrain MSE: {manual_train_mse:.4f}\")\n",
    "print(f\"train R2: {manual_train_r2:.4f}\")\n",
    "\n",
    "# test set\n",
    "X_test_scaled = scaler.transform(df_test[feature_columns].values)\n",
    "y_test_scaled = df_test['price'].values / 1000\n",
    "X_test_bias = np.c_[np.ones(X_test_scaled.shape[0]), X_test_scaled]\n",
    "y_test_pred_manual = X_test_bias @ theta\n",
    "\n",
    "manual_test_mse = mean_squared_error(y_test_scaled, y_test_pred_manual)\n",
    "manual_test_r2 = r2_score(y_test_scaled, y_test_pred_manual)\n",
    "\n",
    "print(f\"\\ntest MSE: {manual_test_mse:.4f}\")\n",
    "print(f\"test R²: {manual_test_r2:.4f}\")\n",
    "\n",
    "# compare\n",
    "print(\"\\ncomparison\")\n",
    "print(f\"sklearn train MSE: {train_mse:.4f}, my MSE: {manual_train_mse:.4f}\")\n",
    "print(f\"sklearn train R²: {train_r2:.4f}, my R²: {manual_train_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9d9ff4-89ac-4ff6-a21f-ab678dc2c047",
   "metadata": {},
   "source": [
    "Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "546e416e-8332-48fb-879f-59d35bb58b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p     train MSE    train R²   test MSE     test R²   \n",
      "-------------------------------------------------------\n",
      "1     57947.5262   0.4967     88575.9785   0.4687    \n",
      "2     54822.6651   0.5238     71791.6795   0.5694    \n",
      "3     53785.1947   0.5329     99833.4838   0.4012    \n",
      "4     52795.7748   0.5415     250979.2743  -0.5053   \n",
      "5     52626.1120   0.5429     570616.9148  -2.4225   \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(df_train['sqft_living'].values.reshape(-1, 1))\n",
    "X_test = scaler.transform(df_test['sqft_living'].values.reshape(-1, 1))\n",
    "\n",
    "# gets sqft_living feature and price\n",
    "y_train = df_train['price'].values / 1000\n",
    "y_test = df_test['price'].values / 1000\n",
    "\n",
    "# trains different polynomial degrees\n",
    "degrees = [1, 2, 3, 4, 5]\n",
    "results = []\n",
    "\n",
    "# creates polynomial features\n",
    "for p in degrees:\n",
    "    X_train_poly = np.ones((X_train.shape[0], 1))\n",
    "    for power in range(1, p + 1):\n",
    "        X_train_poly = np.c_[X_train_poly, X_train ** power]\n",
    "\n",
    "    X_test_poly = np.ones((X_test.shape[0], 1))\n",
    "    for power in range(1, p + 1):\n",
    "        X_test_poly = np.c_[X_test_poly, X_test ** power]\n",
    "\n",
    "    theta = np.linalg.inv(X_train_poly.T @ X_train_poly) @ X_train_poly.T @ y_train\n",
    "\n",
    "    # predictions\n",
    "    y_train_pred = X_train_poly @ theta\n",
    "    y_test_pred = X_test_poly @ theta\n",
    "    \n",
    "    # metrics\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    results.append([p, train_mse, train_r2, test_mse, test_r2])\n",
    "\n",
    "# table\n",
    "print(f\"{'p':<5} {'train MSE':<12} {'train R²':<10} {'test MSE':<12} {'test R²':<10}\")\n",
    "print(\"-\" * 55)\n",
    "for r in results:\n",
    "    print(f\"{r[0]:<5} {r[1]:<12.4f} {r[2]:<10.4f} {r[3]:<12.4f} {r[4]:<10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1a934c-32e4-4cc7-9c0c-3c2b0b71687c",
   "metadata": {},
   "source": [
    "Problem 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36f5c8c1-9916-4fbb-94db-6fe64d2a8822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: MSE = 385968.7732\n",
      "iteration 100: MSE = 70118.9866\n",
      "iteration 200: MSE = 36923.1410\n",
      "iteration 300: MSE = 32390.4390\n",
      "iteration 400: MSE = 31715.1008\n",
      "iteration 500: MSE = 31585.8492\n",
      "iteration 600: MSE = 31544.9992\n",
      "iteration 700: MSE = 31524.5140\n",
      "iteration 800: MSE = 31511.9093\n",
      "iteration 900: MSE = 31503.6358\n",
      "\n",
      "train MSE: 31498.0867\n",
      "train R²: 0.7264\n",
      "test MSE: 57727.6322\n",
      "test R²: 0.6538\n"
     ]
    }
   ],
   "source": [
    "# gradient descent function\n",
    "def gradient_descent(X, y, learning_rate=0.01, num_iterations=1000):\n",
    "    n_samples, n_features = X.shape\n",
    "    theta = np.zeros(n_features)\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        # predictions\n",
    "        y_pred = X @ theta\n",
    "        \n",
    "        # gradient\n",
    "        gradient = (1/n_samples) * X.T @ (y_pred - y)\n",
    "        \n",
    "        # update\n",
    "        theta = theta - learning_rate * gradient\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            mse = mean_squared_error(y, y_pred)\n",
    "            print(f\"iteration {i}: MSE = {mse:.4f}\")\n",
    "    \n",
    "    return theta\n",
    "\n",
    "# use data from problem 3\n",
    "X_train_bias = np.c_[np.ones(X_train_scaled.shape[0]), X_train_scaled]\n",
    "X_test_bias = np.c_[np.ones(X_test_scaled.shape[0]), X_test_scaled]\n",
    "\n",
    "# train with gradient descent\n",
    "theta_gd = gradient_descent(X_train_bias, y_train_scaled, learning_rate=0.01, num_iterations=1000)\n",
    "\n",
    "# predictions and metrics\n",
    "y_train_pred = X_train_bias @ theta_gd\n",
    "y_test_pred = X_test_bias @ theta_gd\n",
    "\n",
    "print(f\"\\ntrain MSE: {mean_squared_error(y_train_scaled, y_train_pred):.4f}\")\n",
    "print(f\"train R²: {r2_score(y_train_scaled, y_train_pred):.4f}\")\n",
    "print(f\"test MSE: {mean_squared_error(y_test_scaled, y_test_pred):.4f}\")\n",
    "print(f\"test R²: {r2_score(y_test_scaled, y_test_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a2e9d8-2b94-45b6-8465-3d0496d995d6",
   "metadata": {},
   "source": [
    "Problem 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f61744a6-3920-4fc1-b089-1073a11f4267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "α=0.001, iter=10: train MSE=374638.3096, R²=-2.2538, test MSE=446476.9659, R²=-1.6779\n",
      "α=0.001, iter=50: train MSE=335057.9782, R²=-1.9101, test MSE=398833.3091, R²=-1.3921\n",
      "α=0.001, iter=100: train MSE=295494.3211, R²=-1.5665, test MSE=351466.1897, R²=-1.1080\n",
      "α=0.01, iter=10: train MSE=294798.7336, R²=-1.5604, test MSE=350525.0973, R²=-1.1024\n",
      "α=0.01, iter=50: train MSE=138295.9152, R²=-0.2011, test MSE=170376.6687, R²=-0.0219\n",
      "α=0.01, iter=100: train MSE=70118.9866, R²=0.3910, test MSE=97486.2448, R²=0.4153\n",
      "α=0.1, iter=10: train MSE=66499.3155, R²=0.4224, test MSE=93559.2950, R²=0.4388\n",
      "α=0.1, iter=50: train MSE=31578.9781, R²=0.7257, test MSE=58012.3167, R²=0.6521\n",
      "α=0.1, iter=100: train MSE=31497.6923, R²=0.7264, test MSE=57725.1857, R²=0.6538\n",
      "\n",
      "α      iter   train MSE      train R²     test MSE       test R²\n",
      "----------------------------------------------------------------------\n",
      "0.001  10     374638.3096    -2.2538      446476.9659    -1.6779\n",
      "0.001  50     335057.9782    -1.9101      398833.3091    -1.3921\n",
      "0.001  100    295494.3211    -1.5665      351466.1897    -1.1080\n",
      "0.01   10     294798.7336    -1.5604      350525.0973    -1.1024\n",
      "0.01   50     138295.9152    -0.2011      170376.6687    -0.0219\n",
      "0.01   100    70118.9866     0.3910       97486.2448     0.4153\n",
      "0.1    10     66499.3155     0.4224       93559.2950     0.4388\n",
      "0.1    50     31578.9781     0.7257       58012.3167     0.6521\n",
      "0.1    100    31497.6923     0.7264       57725.1857     0.6538\n"
     ]
    }
   ],
   "source": [
    "# gradient descent with tracking\n",
    "def gradient_descent_track(X, y, learning_rate, num_iterations):\n",
    "    n_samples, n_features = X.shape\n",
    "    theta = np.zeros(n_features)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for i in range(1, num_iterations + 1):\n",
    "        y_pred = X @ theta\n",
    "        gradient = (1/n_samples) * X.T @ (y_pred - y)\n",
    "        theta = theta - learning_rate * gradient\n",
    "        \n",
    "        if i in [10, 50, 100]:\n",
    "            results[i] = theta.copy()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# different learning rates\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "all_results = []\n",
    "\n",
    "for alpha in learning_rates:\n",
    "    theta_dict = gradient_descent_track(X_train_bias, y_train_scaled, alpha, 100)\n",
    "    \n",
    "    for iteration in [10, 50, 100]:\n",
    "        theta = theta_dict[iteration]\n",
    "        y_train_pred = X_train_bias @ theta\n",
    "        y_test_pred = X_test_bias @ theta\n",
    "        \n",
    "        train_mse = mean_squared_error(y_train_scaled, y_train_pred)\n",
    "        train_r2 = r2_score(y_train_scaled, y_train_pred)\n",
    "        test_mse = mean_squared_error(y_test_scaled, y_test_pred)\n",
    "        test_r2 = r2_score(y_test_scaled, y_test_pred)\n",
    "        \n",
    "        all_results.append([alpha, iteration, train_mse, train_r2, test_mse, test_r2])\n",
    "        print(f\"α={alpha}, iter={iteration}: train MSE={train_mse:.4f}, R²={train_r2:.4f}, test MSE={test_mse:.4f}, R²={test_r2:.4f}\")\n",
    "\n",
    "# table\n",
    "print(\"\\nα      iter   train MSE      train R²     test MSE       test R²\")\n",
    "print(\"-\" * 70)\n",
    "for r in all_results:\n",
    "    print(f\"{r[0]:<7}{r[1]:<7}{r[2]:<15.4f}{r[3]:<13.4f}{r[4]:<15.4f}{r[5]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dae0ef-b84a-487b-b36e-46dde3645fe1",
   "metadata": {},
   "source": [
    "Problem 5.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243deeb4-21a8-4575-b38d-c989debdaa57",
   "metadata": {},
   "source": [
    "The learning rate did affect the convergence speed. With a=0.001, the algorithm learns too slowy, a=0.01, the convergence is moderate and with a=0.1, the convergence is fast achieving R2=0.73 by iteration 100. the number of iterations needed dependend heavily on learning rate. A gradient descent with a=0.1 converges to the same solution as the closed form method from problem 3. This shows that the gradient descent finds the optimal solution when the learning rate is tuned properly. Finally, the MSE values did match closely between both methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f8c333-b1df-468d-8f6b-6a6228f7d7ee",
   "metadata": {},
   "source": [
    "Problem 6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f94d294-44d2-4989-8519-5e8d300e277b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lambda = 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gradient' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lam \u001b[38;5;129;01min\u001b[39;00m lambdas:\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mlambda = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m     theta \u001b[38;5;241m=\u001b[39m ridge_gradient_descent(X_train_bias, y_train_scaled, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m1000\u001b[39m, lam)\n\u001b[0;32m     25\u001b[0m     y_train_pred \u001b[38;5;241m=\u001b[39m X_train_bias \u001b[38;5;241m@\u001b[39m theta\n\u001b[0;32m     26\u001b[0m     y_test_pred \u001b[38;5;241m=\u001b[39m X_test_bias \u001b[38;5;241m@\u001b[39m theta\n",
      "Cell \u001b[1;32mIn[19], line 9\u001b[0m, in \u001b[0;36mridge_gradient_descent\u001b[1;34m(X, y, learning_rate, num_iterations, lambda_reg)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iterations):\n\u001b[0;32m      7\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m X \u001b[38;5;241m@\u001b[39m theta\n\u001b[1;32m----> 9\u001b[0m     theta \u001b[38;5;241m=\u001b[39m theta \u001b[38;5;241m-\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m gradient\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     12\u001b[0m         mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y, y_pred)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gradient' is not defined"
     ]
    }
   ],
   "source": [
    "# ridge gradient descent \n",
    "def ridge_gradient_descent(X, y, learning_rate, num_iterations, lambda_reg):\n",
    "    n_samples, n_features = X.shape\n",
    "    theta = np.zeros(n_features)\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        y_pred = X @ theta\n",
    "        \n",
    "        theta = theta - learning_rate * gradient\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            mse = mean_squared_error(y, y_pred)\n",
    "            print(f\"iteration {i}: MSE = {mse:.4f}\")\n",
    "    \n",
    "    return theta\n",
    "\n",
    "# test lambda values\n",
    "lambdas = [0, 0.1, 1.0, 10.0]\n",
    "\n",
    "for lam in lambdas:\n",
    "    print(f\"\\nlambda = {lam}\")\n",
    "    \n",
    "    theta = ridge_gradient_descent(X_train_bias, y_train_scaled, 0.01, 1000, lam)\n",
    "    \n",
    "    y_train_pred = X_train_bias @ theta\n",
    "    y_test_pred = X_test_bias @ theta\n",
    "    \n",
    "    print(f\"train MSE: {mean_squared_error(y_train_scaled, y_train_pred):.4f}\")\n",
    "    print(f\"train R²: {r2_score(y_train_scaled, y_train_pred):.4f}\")\n",
    "    print(f\"test MSE: {mean_squared_error(y_test_scaled, y_test_pred):.4f}\")\n",
    "    print(f\"test R²: {r2_score(y_test_scaled, y_test_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45ee1ee-7645-4614-94c2-25e12d525000",
   "metadata": {},
   "source": [
    "Problem 6.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fcea1c-b955-4a22-b0cc-44b90d96428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "N = 1000\n",
    "\n",
    "X = np.random.uniform(-2, 2, N)\n",
    "\n",
    "noise = np.random.normal(0, np.sqrt(2), N)\n",
    "Y = 1 + 2*X + noise\n",
    "\n",
    "# add bias term\n",
    "X_bias = np.c_[np.ones(N), X]\n",
    "\n",
    "# closed-form ridge regression function\n",
    "def ridge_regression(X, y, lambda_reg):\n",
    "    n_features = X.shape[1]\n",
    "    I = np.eye(n_features)\n",
    "    theta = np.linalg.inv(X.T @ X + lambda_reg * I) @ X.T @ y\n",
    "    return theta\n",
    "\n",
    "# test lambda values\n",
    "lambdas = [0, 1, 10, 100, 1000, 10000]\n",
    "results = []\n",
    "\n",
    "print(\"λ        intercept   slope      MSE        R²\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for lam in lambdas:\n",
    "    theta = ridge_regression(X_bias, Y, lam)\n",
    "    \n",
    "    Y_pred = X_bias @ theta\n",
    "    \n",
    "    mse = mean_squared_error(Y, Y_pred)\n",
    "    r2 = r2_score(Y, Y_pred)\n",
    "    \n",
    "    results.append([lam, theta[0], theta[1], mse, r2])\n",
    "    print(f\"{lam:<8} {theta[0]:<11.4f} {theta[1]:<10.4f} {mse:<10.4f} {r2:.4f}\")\n",
    "\n",
    "print(\"\\ntrue values: intercept = 1.0, slope = 2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bb26ba-6273-40bd-9141-e2df05eccdf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
